{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e8a52cf",
   "metadata": {},
   "source": [
    "# Dataset parser\n",
    "\n",
    "This is notebook with code used to parse dataset of articles fo shpringer journals on comupter science. \n",
    "To do this it also uses the list of journals located in file 'data/journal_names.txt'\n",
    "\n",
    "Link for the data: https://sn-scigraph.figshare.com/articles/dataset/Dataset_Articles/7376468\n",
    "\n",
    "It contains functions what does:\n",
    "\n",
    "1. Check if journals are present in the file\n",
    "2. Parse the dataset to find the articles form the journals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd4ebd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b40a8030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "962"
     ]
    }
   ],
   "source": [
    "# Loading journal list\n",
    "journals = set()\n",
    "\n",
    "for i in range(963):\n",
    "    print('\\r' + str(i), end = '')\n",
    "    fl = open(\"articles/articles_\" + str(i) + \".jsonl\")\n",
    "    for line in fl:\n",
    "        data = json.loads(line)\n",
    "        \n",
    "        for el in data.get('isPartOf', []):\n",
    "            if 'name' in el:\n",
    "                journals.add(el['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd1275f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name(string):\n",
    "    pos = string.find('.')\n",
    "    return string[pos + 2:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6994f716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cheking if journals exist\n",
    "journal_names = []\n",
    "with open('data/journal_names.txt') as fl:\n",
    "    for el in fl:\n",
    "        if not get_name(el) in journals:\n",
    "            print(el)\n",
    "        else:\n",
    "            journal_names.append(get_name(el))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc4285c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "907"
     ]
    }
   ],
   "source": [
    "# Loading articles\n",
    "df = {'journal':[], 'date_published':[], 'name':[], 'keywords':[], 'url':[], 'abstract':[]}\n",
    "\n",
    "for i in range(963):\n",
    "    print('\\r' + str(i), end = '')\n",
    "    fl = open(\"articles/articles_\" + str(i) + \".jsonl\")\n",
    "    for line in fl:\n",
    "        data = json.loads(line)\n",
    "        flag = True\n",
    "        for el in data.get('isPartOf', []):\n",
    "            if ('name' in el) and (el['name'] in journal_names) and flag:\n",
    "                flag = False\n",
    "                df['journal'].append(el['name'])\n",
    "                df['name'].append(data.get('name', None))\n",
    "                df['url'].append(data.get('url', None))\n",
    "                df['date_published'].append(data.get('datePublished', None))\n",
    "                df['keywords'].append(data.get('keywords', None))\n",
    "                df['abstract'].append(data.get('description', None))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bc0baf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the dataset\n",
    "df1 = pd.DataFrame(df)\n",
    "df1.to_csv('data/data_table.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c42955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting further years from the table\n",
    "df1 = pd.read_csv(\"data/data_table.csv\", index_col=0)\n",
    "df1['year_published'] = list(map(lambda x: int(x.split('-')[0]), df1['date_published']))\n",
    "df = df1[df1['year_published'] >= 2003]\n",
    "df = df.reset_index().drop(columns=['index'])\n",
    "df.to_csv('data/res_table.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
